---
title: "Avian Window Collisions"
author: "Mason Youngblood"
output: github_document
---

![](https://www.smith.edu/sites/default/files/styles/news_header/public/media/-news/Birdfilm2.jpg?itok=3ymslT-_){width=30%}

```{r setup-chunk, include=FALSE}
knitr::opts_chunk$set(dev = "png", dpi = 300)
```

## Intro

These avian window collision data were collected by Ar Kornreich from various states in the northeastern US. `Window.Collision.R-Ready.res.csv` contains the original data that is used throughout the analysis, and `WinCol_data_Suppmat.xlsx` is an additional file that contains full descriptions of injuries and methods for injury categorization, locality of each case, and population density groupings. The data are comprised of individual cases of birds that were brought into rehabilitation centers, with information about species, age, sex, injuries, and the number of days that they survived. We will be identifying the major drivers of rehabilitation in two ways: (1) using logistic and Poisson models of release and treatment time, and (2) using a right-censored survival model of treatment time where the censored cases are those where birds died and could not be released.^[An overview of data censoring can be found [here](https://www.youtube.com/watch?v=K-_sblQZ5rE).] All models will be run in `Stan` using `brms`.

For the survival analysis, we will be using the parameteric approach in `brms` described by [A. Solomon Kurz](https://bookdown.org/content/4857/god-spiked-the-integers.html#bonus-survival-analysis) and inspired by [Richard McElreath](https://youtu.be/p7g-CgGCS34?t=1424).^[An interesting alternative using Poisson modeling can be found [here](https://github.com/paul-buerkner/brms/issues/230).] We will start out with the exponential distribution, which is often used to model survival data because it fits the waiting times for events from a [Poisson distribution](https://stats.stackexchange.com/questions/2092/relationship-between-poisson-and-exponential-distribution), but we will also use the [Weibull and Gamma distributions](https://onlinelibrary.wiley.com/doi/10.1111/eth.13225).^[An overview of the shapes of these distributions can be found [here](https://devinincerti.com/2019/06/18/parametric_survival.html#shapes-of-hazard-functions).]

The specification for an exponential survival model with a log link function is as follows:

$$
\displaylines{
T_i|D_i = 1 \sim \mbox{Exponential}(\lambda_i)\\
T_i|D_i = 0 \sim \mbox{Exponential-CCDF}(\lambda_i)\\
\lambda_i = 1/\mu_i\\
\mbox{log } \mu_i = \mbox{...}}
$$

Where *T* is treatment time, *D* is whether the bird died (1) or was released (0), and "..." is the rest of the model specification. Death (*D* = 1) is modeled with an exponential function, whereas release (*D* = 0) is modeled with a exponential complementary cumulative distribution function (CCDF). CCDF functions are used to model the probability that the even has *not* yet happened. The Weibull and Gamma versions of the model only vary in the distribution family of the top two lines. We will also check whether it makes sense to do the analysis where *D* is whether the bird died (0) or was released (1), so where release is censored rather than death.

It is important to note that our data violate the assumption of [non-informative](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3275994/) [censoring](https://www.nature.com/articles/s41571-020-0368-0), or the assumption that the censored variable (death) is independent of the event variable (release). This is because birds that die presumably had worse injuries or health, and would have taken longer to be released if they had survived. There are [several](https://onlinelibrary.wiley.com/doi/10.1002/sim.6274) [imputation](https://onlinelibrary.wiley.com/doi/10.1002/sim.3480) [methods](https://academic.oup.com/biostatistics/article/13/2/341/263988) that replace the event times of censored cases to account for bias introduced by non-informative censoring, including the R package `InformativeCensoring`. Unfortunately, these methods are designed for cases where full data are available, or where missing data imputation is not in use. In this study we will not be using specialized imputation for informative censoring, so the overall release curves will be systematically biased towards shorter times. We do not have a reason to expect this to bias predictor estimates.

## Data Cleanup

Let's load the packages we need and the data.

```{r message = FALSE}
#load packages
library(brms)
library(mice)
library(ggplot2)
library(dagitty)
library(ggdag)
library(survival)
library(ggfortify)
library(ggrepel)
library(flexsurv)
library(bayesplot)
library(cowplot)

#load data
raw_data <- read.csv("Window.Collision.R-Ready.res.csv")
```

Here is a plot of the familes we have in the data.

```{r, fig.height = 4, fig.width = 6}
#using code adapted from ar
wincol <- raw_data[!(raw_data$MayHBC == "TRUE"), ]
fam_mass <- aggregate(wincol$Avg.Sp.Mass.g, by = list(wincol$Family), FUN = mean, na.rm = TRUE, na.action = NULL, nfrequency = 1)
fam_mass$Freq <- table(wincol$Family)
ggplot(fam_mass, aes(x, Freq, label = Group.1)) + 
  geom_text_repel(size = 3) + scale_x_continuous(trans = "log10") + 
  scale_y_continuous(trans = "log10", limits = c(0.8, 460)) + 
  xlab("Average Mass (g) ") + ylab("Number of Cases") + theme_linedraw(base_size = 9) + 
  annotation_logticks()
```

Before moving forward, we should think about the causal structure of the data. Below is a directed acyclic graph (DAG) of the variables for which we have decent coverage. The red node is our outcome variable, survival time, the black nodes comprise the adjustment set needed to estimate the effects of funding, mass, and age on survival time, and the gray nodes are the variables that are unnecessary to include.

```{r echo = FALSE, message = FALSE}
#define categories of nodes
exposure <- c("FUND", "MASS", "AGE", "SZN")
outcome <- c("RLS")
other <- c("STAT", "ORG", "SPEC", "FAM")

#create DAG
dag <- dagify(
  FUND ~ ORG + STAT,
  RLS ~ ORG + FUND + SPEC + MASS + AGE + SZN,
  AGE ~ SZN,
  SPEC ~ SZN + FAM + STAT,
  MASS ~ SPEC
)

#adjustment set required for direct effects of interest
adjustmentSets(dag, exposure = c("FUND", "MASS", "SZN"), outcome = c("RLS"))

#plot DAG
set.seed(12345)
dag_plot <- ggdag(dag) + theme_void()
colors <- as.character(ifelse(dag_plot$data$name %in% outcome, 1, ifelse(dag_plot$data$name %in% exposure, 2, 3)))
dag_plot$layers[[3]]$mapping <- aes(colour = colors)
dag_plot + scale_color_manual(values = c("red", "blue", "black")) + theme(legend.position = "none")
```

According to the results of `adjustmentSets`, we do not need to condition on any other variables besides our exposure variables (in blue) to estimate their causal effects on our outcome variable (in red).^[A good overview about how to interpret DAGs can be found [here](https://stats.stackexchange.com/questions/445578/how-do-dags-help-to-reduce-bias-in-causal-inference).] So we will only include mass, funding, season, and age in the modeling, but will keep the other variables for imputation.

Let's move on to subsetting and cleaning the data. We will temporarily replace and/or remove some of the incorrectly formatted data until we have the finalized version.

```{r}
#subset data
data <- data.frame(treatment = raw_data$Treatment.Time,
                   mass = raw_data$Avg.Sp.Mass.g,
                   species = raw_data$Species,
                   family = raw_data$Family,
                   age = raw_data$Age,
                   sex = raw_data$Sex,
                   funding = raw_data$RhbFund,
                   org = raw_data$Facility,
                   state = sapply(1:nrow(raw_data), function(x){substr(raw_data$Location[x], nchar(raw_data$Location[x])-1, nchar(raw_data$Location[x]))}),
                   season = raw_data$Season,
                   death = ifelse(raw_data$Disposition %in% c("Dead on Arrival", "Died", "Euthanized"), 1, 0),
                   release = ifelse(raw_data$Disposition %in% c("Kept for Education", "Released"), 1, 0))

#add +1 to treatment times to there are no zeros
data$treatment <- data$treatment + 1

#replace uncertain species with NA and convert to factor
data$species[which(nchar(data$species) != 4)] <- NA
data$species <- factor(data$species)

#convert state, family, season, and organization to factor
data$state <- factor(data$state)
data$family <- factor(data$family)
data$org <- factor(data$org)
data$season <- factor(data$season, levels = c("Spring", "Summer", "Fall", "Winter"))

#clean up age and sex and convert to factors
data$age[which(data$age == "Unknown")] <- NA
data$sex[which(data$sex == "Unknown")] <- NA
data$age <- factor(data$age, levels = c("Juvenile", "Adult"))
data$sex <- factor(data$sex)

#scale mass and funding
data$mass <- as.numeric(scale(data$mass))
data$funding <- as.numeric(scale(data$funding))
```

## Imputation

There are several variables for which we have incomplete data: state (`r paste0(signif(length(which(is.na(data$state)))/nrow(data)*100, 2), "%")`), age (`r paste0(signif(length(which(is.na(data$age)))/nrow(data)*100, 2), "%")`), organization type (`r paste0(signif(length(which(is.na(data$org)))/nrow(data)*100, 2), "%")`), funding (`r paste0(signif(length(which(is.na(data$funding)))/nrow(data)*100, 2), "%")`), treatment time (`r paste0(signif(length(which(is.na(data$treatment)))/nrow(data)*100, 2), "%")`), and sex (`r paste0(signif(length(which(is.na(data$sex)))/nrow(data)*100, 2), "%")`). Sex is missing far too much of the data and will be excluded from analysis. For everything else, we will handle missingness using the multiple imputation approach recommended by [Paul BÃ¼rkner](https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html#imputation-before-model-fitting). First, we will use multiple imputation with random forest machine learning to generate 10 different imputed versions of our data. Then, we will fit our models to each imputed dataset separately and pool the results across all of the models.

Let's impute our 10 datasets and save them for future use.

```{r eval = FALSE}
#run imputation
set.seed(12345)
num_imp <- 10
imp_data <- mice(data[, c(1, 2, 5, 7, 10:12)], method = "rf", m = num_imp)

#save imputed data
save(imp_data, file = "imp_data.RData")
```

```{r echo = FALSE}
#load imputed data
load("imp_data.RData")
```

## Logistic & Poisson Models

```{r, eval = FALSE}
#run logistic model with release as outcome variable
release_model <- brm_multiple(data = imp_data,
                              family = bernoulli(link = "logit"),
                              release ~ mass + age + funding + season,
                              cores = 4, chains = 4, iter = 5000,
                              prior = c(set_prior("normal(0, 0.5)", class = "b")))

#run poisson model with treatment time as outcome variable
treatment_model <- brm_multiple(data = imp_data,
                                family = poisson,
                                treatment ~ mass + age + funding + season,
                                cores = 4, chains = 4, iter = 5000,
                                prior = c(set_prior("normal(0, 0.5)", class = "b")))

#save models
standard_models <- list(release = release_model, treatment = treatment_model)
save(standard_models, file = "standard_models.RData")
```

```{r, echo = FALSE}
load("standard_models.RData")
release_model <- standard_models[[1]]
treatment_model <- standard_models[[2]]
```

```{r, echo = FALSE}
#create tables of effects
rls_table <- as.data.frame(fixef(release_model)[-1, -2])
rls_table$signif <- sapply(1:nrow(rls_table), function(x){ifelse(rls_table[x, 2]*rls_table[x, 3] > 0, "*", "")})
rownames(rls_table) <- c("Mass", "Age", "Funding", "Season: Summer", "Season: Fall", "Season: Winter")
colnames(rls_table) <- c("Est.", "2.5%", "97.5%", "")
knitr::kable(rls_table, digits = 2, caption = "Release Model")
```

```{r, echo = FALSE}
#create tables of effects
trt_table <- as.data.frame(fixef(treatment_model)[-1, -2])
trt_table$signif <- sapply(1:nrow(trt_table), function(x){ifelse(trt_table[x, 2]*trt_table[x, 3] > 0, "*", "")})
rownames(trt_table) <- c("Mass", "Age", "Funding", "Season: Summer", "Season: Fall", "Season: Winter")
colnames(trt_table) <- c("Est.", "2.5%", "97.5%", "")
knitr::kable(trt_table, digits = 2, caption = "Treatment Model")
```

As described above, the Rhats from `brm_multiple` are unreliable so we have to check the Rhats for each of the 10 imputed datasets, which are all approaching 1.

```{r}
#get rhats from release submodels
rls_rhats <- release_model$rhats[, 2:7]
rls_rhats <- cbind(1:10, rls_rhats)
colnames(rls_rhats) <- c("Imputation", "Mass", "Age", "Funding", "Season: Summer", "Season: Fall", "Season: Winter")
knitr::kable(rls_rhats, digits = 4, caption = "Release Rhats")
```

```{r}
#get rhats from treatment submodels
trt_rhats <- treatment_model$rhats[, 2:7]
trt_rhats <- cbind(1:10, trt_rhats)
colnames(trt_rhats) <- c("Imputation", "Mass", "Age", "Funding", "Season: Summer", "Season: Fall", "Season: Winter")
knitr::kable(trt_rhats, digits = 4, caption = "Treatment Rhats")
```

```{r, echo = FALSE, fig.height = 3, fig.width = 10, message = FALSE, warning = FALSE}
color_scheme_set("gray")

a <- mcmc_intervals(release_model, prob = 0.95, pars = c("b_mass", "b_ageAdult", "b_funding"), point_size = 2) + 
  xlim(-0.35, 0.35) + theme_linedraw(base_size = 9) + scale_y_discrete(limits = c("b_funding", "b_ageAdult", "b_mass"), labels = c("Funding", "Age", "Mass")) + 
  geom_vline(xintercept = 0, lty = "dashed") + xlab("") + theme(panel.grid.major.y = element_blank()) + ggtitle("Release ~ ...")
a$layers[[3]]$aes_params$colour <- "black"
a$layers[[3]]$aes_params$linewidth <- 0.5
a$layers[[2]]$aes_params$colour <- "black"
a$layers[[2]]$aes_params$linewidth <- 0
a$layers[[4]]$aes_params$fill <- "black"
a$layers[[4]]$aes_params$colour <- "black"

b <- mcmc_intervals(treatment_model, prob = 0.95, pars = c("b_mass", "b_ageAdult", "b_funding"), point_size = 2) + 
  xlim(-0.35, 0.35) + theme_linedraw(base_size = 9) + scale_y_discrete(limits = c("b_funding", "b_ageAdult", "b_mass"), labels = c("Funding", "Age", "Mass")) + 
  geom_vline(xintercept = 0, lty = "dashed") + xlab("Effect") + theme(panel.grid.major.y = element_blank()) + ggtitle("Treatment ~ ...")
b$layers[[3]]$aes_params$colour <- "black"
b$layers[[3]]$aes_params$linewidth <- 0.5
b$layers[[2]]$aes_params$colour <- "black"
b$layers[[2]]$aes_params$linewidth <- 0
b$layers[[4]]$aes_params$fill <- "black"
b$layers[[4]]$aes_params$colour <- "black"

c <- conditional_effects(release_model, effects = "season", spaghetti = TRUE)
c <- plot(c, plot = FALSE)[[1]] + theme_linedraw(base_size = 9) + xlab("Season") + ylab("Probability of Release") + theme(panel.grid.major.x = element_blank()) + ggtitle("Release ~ ...")
c$layers[[1]]$aes_params$size <- 2

d <- conditional_effects(treatment_model, effects = "season", spaghetti = TRUE)
d <- plot(d, plot = FALSE)[[1]] + theme_linedraw(base_size = 9) + xlab("Season") + ylab("Treatment Time") + theme(panel.grid.major.x = element_blank()) + ggtitle("Treatment ~ ...")
d$layers[[1]]$aes_params$size <- 2

plot_grid(plot_grid(a, b, nrow = 2), c, d, nrow = 1, labels = c("A", "B"))
```

## Survival Models

Before constructing our full survival models, let's run frequentist versions using one of the imputed datasets to see how well the exponential, Weibull, and Gamma distributions fit the data. With `Surv` from `flexsurvreg`, [the first argument is the treatment time and second is 1 if the event of interest and 0 if censored](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html).

```{r}
#create one complete imputed dataset
imp_data_comp <- complete(imp_data)

#run three frequentist survival models where death is censored
freq_exp <- flexsurvreg(Surv(treatment, release) ~ 1, data = imp_data_comp, dist = "exponential")
freq_wei <- flexsurvreg(Surv(treatment, release) ~ 1, data = imp_data_comp, dist = "weibull")
freq_gam <- flexsurvreg(Surv(treatment, release) ~ 1, data = imp_data_comp, dist = "gamma")

#run three frequentist survival models where release is censored
freq_exp_alt <- flexsurvreg(Surv(treatment, death) ~ 1, data = imp_data_comp, dist = "exponential")
freq_wei_alt <- flexsurvreg(Surv(treatment, death) ~ 1, data = imp_data_comp, dist = "weibull")
freq_gam_alt <- flexsurvreg(Surv(treatment, death) ~ 1, data = imp_data_comp, dist = "gamma")
```

```{r echo = FALSE}
#plot models
par(mar = c(4, 4, 0.5, 0.5))
plot(freq_exp, ci = FALSE, conf.int = FALSE, ylab = "Proportion Unreleased", xlab = "Treatment Days", xlim = c(0, 100), col = "#009E73")
lines(freq_wei, col = "#0072B2", ci = FALSE)
lines(freq_gam, col = "#D55E00", ci = FALSE)
legend("topright", lty = c(1, 1, 1), lwd = c(2, 2, 2), col = c("#009E73", "#0072B2", "#D55E00"), c("Exponential", "Weibull", "Gamma"))
```

```{r echo = FALSE}
#plot models
par(mar = c(4, 4, 0.5, 0.5))
plot(freq_exp_alt, ci = FALSE, conf.int = FALSE, ylab = "Proportion Alive", xlab = "Treatment Days", xlim = c(0, 100), col = "#009E73")
lines(freq_wei_alt, col = "#0072B2", ci = FALSE)
lines(freq_gam_alt, col = "#D55E00", ci = FALSE)
legend("topright", lty = c(1, 1, 1), lwd = c(2, 2, 2), col = c("#009E73", "#0072B2", "#D55E00"), c("Exponential", "Weibull", "Gamma"))
```

Only the models where death is censored and release is the outcome fit the data, so we will move forward accordingly.

```{r}
#compare AIC for three models
AIC(freq_exp, freq_wei, freq_gam)
```

All three do a decent job but the Weibull model has the lowest AIC. Let's check the output of the full frequentist Weibull model with predictors.

```{r}
#run full frequentist model
freq_wei_full <- flexsurvreg(Surv(treatment, release) ~ mass + age + funding + season, data = imp_data_comp, dist = "weibull")
```

We will only run the full Bayesian model as a Weibull distribution.

```{r eval = FALSE}
#run bayesian weibull model
wei_model <- brm_multiple(data = imp_data,
                          family = weibull,
                          treatment|cens(death) ~ mass + age + funding + season,
                          cores = 4, chains = 4, iter = 5000,
                          prior = c(set_prior("normal(0, 0.5)", class = "b")))

#save model
save(wei_model, file = "wei_model.RData")
```

```{r echo = FALSE}
#load model
load("wei_model.RData")
```

Note that the effective sample sizes and Rhats from `brm_multiple` are [known to be unreliable](https://discourse.mc-stan.org/t/brm-multiple-not-converging-though-separate-brm-models-do/8740). If we instead take a look at the Rhats for each submodel we can see that they are all close to 1, which indicates that the individual models have converged.

```{r}
#get rhats from individual submodels
wei_model$rhats
```

Here are the results of the Weibull model.

```{r messages = FALSE, warning = FALSE}
#print summary
summary(wei_model)
```

Let's plot all of these effects in a more intuitive way.

Each line is a posterior prediction averaged across the Weibull models fit to the imputed datasets. In the first plot, the color is whether the predicted survival curve is for an individual with mass +2 SDs, 0 SDs or +2 SDs around the mean. The other two are for the two categories of age and for funding.

```{r echo = FALSE}
#define function for plotting posteriors from the survival models
posterior_survival <- function(condition, input, times, bounds = TRUE){
  if(bounds){
    lower <- 1 - pexp(times, rate = 1/exp(input[1]))
    median <- 1 - pexp(times, rate = 1/exp(input[2]))
    upper <- 1 - pexp(times, rate = 1/exp(input[3]))
    return(data.frame(condition, times, lower, median, upper))
  } else{
    temp <- lapply(1:length(input), function(x){data.frame(condition = condition, group = x, times = times, prob = 1 - pexp(times, rate = 1/exp(input[x])))})
    return(do.call("rbind", temp))
  }
}
```

```{r echo = FALSE}
#get all combinations of age and season
age_szn_combos <- expand.grid(c("Adult", "Juvenile"), c("Spring", "Summer", "Winter", "Fall"))

#compile mass data for plotting
mass_plot_data <- do.call(rbind, list(
  posterior_survival("1", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = 0, mass = -2), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("2", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("3", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = 0, mass = 2), re_formula = NA)), 1000), 0:40, FALSE)
))

#plot it
ggplot(data = mass_plot_data, aes(x = times, y = prob)) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  geom_line(aes(group = interaction(factor(group), factor(condition)), color = factor(condition)), alpha = 0.05) + 
  theme_linedraw() + 
  scale_color_manual(name = "Mass", labels = c("-2 SD", "0 SD", "+2 SD"), values = c("#D55E00", "#0072B2", "#009E73")) + 
  ylab("Proportion Unreleased") + xlab("Days of Treatment") + 
  guides(color = guide_legend(override.aes = list(alpha = 1)))
```

```{r echo = FALSE}
#compile age data for plotting
age_plot_data <- do.call(rbind, list(
  posterior_survival("1", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = "Juvenile", season = c("Spring", "Summer", "Fall", "Winter"), funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("2", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = "Adult", season = c("Spring", "Summer", "Fall", "Winter"), funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE)
))

#plot it
ggplot(data = age_plot_data, aes(x = times, y = prob)) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  geom_line(aes(group = interaction(factor(group), factor(condition)), color = factor(condition)), alpha = 0.05) + 
  theme_linedraw() + 
  scale_color_manual(name = "Age", labels = c("Juvenile", "Adult"), values = c("#D55E00", "#0072B2")) + 
  ylab("Proportion Unreleased") + xlab("Days of Treatment") + 
  guides(color = guide_legend(override.aes = list(alpha = 1)))
```

```{r echo = FALSE}
#compile season data for plotting
szn_plot_data <- do.call(rbind, list(
  posterior_survival("1", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = c("Juvenile", "Adult"), season = "Spring", funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("2", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = c("Juvenile", "Adult"), season = "Summer", funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("3", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = c("Juvenile", "Adult"), season = "Fall", funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("4", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = c("Juvenile", "Adult"), season = "Winter", funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE)
))

#plot it
ggplot(data = szn_plot_data, aes(x = times, y = prob)) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  geom_line(aes(group = interaction(factor(group), factor(condition)), color = factor(condition)), alpha = 0.05) + 
  theme_linedraw() + 
  scale_color_manual(name = "Season", labels = c("Spring", "Summer", "Fall", "Winter"), values = c("#D55E00", "#0072B2", "#009E73", "#CC79A7")) + 
  ylab("Proportion Unreleased") + xlab("Days of Treatment") + 
  guides(color = guide_legend(override.aes = list(alpha = 1)))
```

```{r echo = FALSE}
#get all combinations of age and season
age_szn_combos <- expand.grid(c("Adult", "Juvenile"), c("Spring", "Summer", "Winter", "Fall"))

#compile funding data for plotting
funding_plot_data <- do.call(rbind, list(
  posterior_survival("1", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = -2, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("2", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = 0, mass = 0), re_formula = NA)), 1000), 0:40, FALSE),
  posterior_survival("3", sample(c(posterior_linpred(wei_model, newdata = data.frame(age = age_szn_combos[, 1], season = age_szn_combos[, 2], funding = 2, mass = 0), re_formula = NA)), 1000), 0:40, FALSE)
))

#plot it
ggplot(data = funding_plot_data, aes(x = times, y = prob)) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  geom_line(aes(group = interaction(factor(group), factor(condition)), color = factor(condition)), alpha = 0.05) + 
  theme_linedraw() + 
  scale_color_manual(name = "Funding", labels = c("-2 SD", "0 SD", "+2 SD"), values = c("#D55E00", "#0072B2", "#009E73")) + 
  ylab("Proportion Unreleased") + xlab("Days of Treatment") + 
  guides(color = guide_legend(override.aes = list(alpha = 1)))
```
